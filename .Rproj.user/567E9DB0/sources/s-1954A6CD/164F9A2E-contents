# VARIABLES ALEATORIAS Y DISTRIBUCIONES DE PROBABILIDAD
# Objetivo: conocer los conceptos estadísticos necesarios para entender
# p-values e intervalos de confianza.

# Ejemplo: http://diabetes.diabetesjournals.org/content/53/suppl_3/S215.full
# Experimento: asignación aleatoria de los ratones seleccionados a una dieta.

# "El peso corporal fue mayor en los ratones alimentados con la dieta alta en grasas
# después de la primera semana, debido a una mayor ingesta en combinación
# con una menor eficiencia metabólica"

# El respaldo de lo anterior se soporta en:
# "Ya durante la primera semana después de la introducción de la dieta alta en grasas,
# el peso corporal aumentó significativamente en los ratones alimentados con dieta
# rica en grasas (+1.6 +/- 0.1 g) que en los ratones alimentados con dieta
# normal (+ 0.2 +/- 0.1 g; P <0.001)"

# ¿Qué significa P <0.001?
# ¿Por qué se incluye "+/-"?


# INFERENCIA
# Fijar directorio de trabajo
setwd("~/Documents/OneDrive/R/Cursos/Intro_estadistica/BD")

# Cargar archivo
dat <- read.csv("femaleMiceWeights.csv")

# ¿Los ratones HF son los más pesados? Comenten

# Calcular el promedio de cada grupo
library(dplyr)
control <- filter(dat,Diet=="chow") %>% select(Bodyweight) %>% unlist  # ¿Por qué es control?
treatment <- filter(dat,Diet=="hf") %>% select(Bodyweight) %>% unlist  # ¿Por qué es tratamiento?
print( mean(treatment) )
print( mean(control) )
obsdiff <- mean(treatment) - mean(control)   # DIFERENCIA DE PROMEDIOS/MEDIAS  ==> ¿A qué número tiende la diferencia cuándo las medias son iguales?
print(obsdiff)

# Los ratones con dietas HF son aproximadamente un 10% más pesados.
# ¿Es esto suficiente? Comentar
# ¿Por qué necesitamos los valores P y los intervalos de confianza?


# Razón: estos promedios son variables aleatorias. Si repetimos el experimento y
# seleccionamos otros 24 ratones y los asignamos aleatoriamente a cada dieta,
# obtendremos medias diferentes. Cada vez que repitamos el experimento obtendremos medias
# diferentes. Este tipo de cantidades se llaman variables aleatorias.

# VARIABLES ALEATORIAS
# Imaginemos que tenemos TODOS los registros del peso de los ratones hembra del grupo
# de control: esto en estadística es la POBLACIÓN. En la práctica casi nunca tenemos acceso
# a la población.
population <- read.csv("femaleControlsPopulation.csv")
# usar unlist para convertirlo en un vector numérico
population <- unlist(population) 

# Obtener tres muestras de tamaño 12 y estimar sus medias
control <- sample(population,12)
mean(control)

control <- sample(population,12)
mean(control)

control <- sample(population,12)
mean(control)

# HIPÓTESIS NULA
# Retomemos la diferencia de promedios "obsdiff"
# ¿Cómo sabemos que esta diferencia se debe a la dieta?
# ¿Qué sucede si le damos a los 24 ratones la misma dieta?
# ¿Veremos una diferencia así de grande?
# Este escenario es la "Hipótesis nula"
# El nombre NULO es para recordarnos que actuamos como escépticos: damos crédito a la
# posibilidad de que no haya diferencia.

# Dado que tenemos a la población de dieta normal, podemos observar tantos valores como
# queramos de la diferencia de los promedios cuando la dieta no tiene efecto:

# 12 ratones de control
control <- sample(population,12)
# Otros 12 ratones de control que "actuarán" como si no lo fueran
treatment <- sample(population,12)
print(mean(treatment) - mean(control))

# Hagamos esto 10,000 veces
n <- 10000
null <- vector("numeric",n)
for (i in 1:n) {
        control <- sample(population,12)
        treatment <- sample(population,12)
        null[i] <- mean(treatment) - mean(control)
}

null

# Los valores de NULL forman la Distribución Nula.

# ¿Qué porcentaje de los 10,000 registros de NULL son más grandes que OBSDIFF?
mean(null >= obsdiff)

# Solo un pequeño porcentaje de las 10 mil simulaciones. Como escépticos concluimos que
# cuando no hay efecto en la dieta, vemos una diferencia tan grande como de OBSDIFF
# solo el 1.5% Del tiempo. Esto es lo que se conoce como un valor p.

# DISTRIBUCIONES
# Distribución: descripción compacta de muchos números
# Ejemplo: supongamos que medimos la altura de todos los hombres de una población
# Imaginemos que necesitamos describir estos números a un extraterrestre que no tiene idea
# de lo que son estás alturas y que nunca ha visitado la tierra. Supongamos que todas las
# alturas están en la siguiente base de datos:

install.packages("UsingR")
library(UsingR)

data(father.son,package="UsingR")
x <- father.son$fheight

# Una manera de resumir estos números es simplificar la lista de todos ellos para que las
# vea el extraterrestre: 10 alturas de 1,078 seleccionadas al azar:
round(sample(x,10),1)


# FUNCIÓN DE DISTRIBUCIÓN ACUMULADA

# Al revisar estos números empezamos a tener una idea aproximada de cómo se ve toda la
# lista, pero sin duda es ineficiente. Podemos mejorar rápidamente este enfoque
# definiendo y visualizando una distribución. Para definir una distribución calculamos,
# para todos los valores posibles de "a", la proporción de números en nuestra lista que
# están por debajo de "a":

# F(a) = Pr(x<=a)

# Esta es la función de distribución acumulada (FDA/CDF)
# Las FDAE/ECDF (empírico) provienen de datos.

# FDAE/ECDF de las alturas:
smallest <- floor( min(x) )
largest <- ceiling( max(x) )
values <- seq(smallest, largest,len=300)
heightecdf <- ecdf(x)
plot(values, heightecdf(values), type="l",
     xlab="a (Height in inches)",ylab="Pr(x <= a)")

# HISTOGRAMAS

# En la práctica se utilizan más los histogramas que las FDAE
# Los histogramas muestran la proporción de valores en intervalos:

# Pr(a <= x <= b) = F(b)-F(a)��� F(a)

# Trazar estas alturas como barras es lo que llamamos un histograma.
# Es un gráfico más útil porque usualmente estamos más interesados en los intervalos,
# tales y tales porcentajes están entre 70 pulgadas y 71 pulgadas, etc., en lugar del
# porcentaje que es menor a altura particular. También es más fácil distinguir los
# diferentes tipos (familias) de distribuciones observando los histogramas.

hist(x)

# Podemos mejorar la gráfica
bins <- seq(smallest, largest)
hist(x,breaks=bins,xlab="Height (in inches)",main="Adult men heights")


# DISTRIBUCIÓN DE PROBABILIDAD

# Resumir las listas de números es un poderoso uso de la distribución.
# Un uso aún más importante es describir los posibles resultados de una variable aleatoria.
# A diferencia de una lista fija de números, en la realidad no observamos todos los resultados
# posibles de variables aleatorias, así que en vez de describir proporciones, describimos
# probabilidades. Por ejemplo, si seleccionamos una altura aleatoria de nuestra lista,
# la probabilidad de que caiga entre a y b se denota con:

# Pr(a <= X <= b) = F(b) - F(a)

# Tenga en cuenta que la X ahora está en mayúscula para distinguirla como una variable aleatoria
# y que la ecuación anterior define la distribución de probabilidad de la variable aleatoria.
# Conocer esta distribución es increíblemente útil en la ciencia. Por ejemplo, en el caso anterior,
# si conocemos la distribución de la diferencia en la media de los pesos del ratón cuando la hipótesis
# nula es verdadera (distribución nula), podemos calcular la probabilidad de observar un valor
# tan grande como lo hicimos, referido como un valor p. En una sección anterior ejecutamos lo que se
# llama una simulación de Monte Carlo y obtuvimos 10.000 resultados de la variable aleatoria bajo la
# hipótesis nula. Repetiremos el ciclo anterior, pero esta vez agreguemos un punto a la figura cada vez
# que volvamos a ejecutar el experimento. Si ejecuta este código, puede ver que la distribución nula se
# forma cuando los valores observados se acumulan uno encima del otro.

n <- 100
#install.packages("rafalib")
library(rafalib)
nullplot(-5,5,1,30, xlab="Observed differences (grams)", ylab="Frequency")
totals <- vector("numeric",11)
for (i in 1:n) {
  control <- sample(population,12)
  treatment <- sample(population,12)
  nulldiff <- mean(treatment) - mean(control)
  j <- pmax(pmin(round(nulldiff)+6,11),1)
  totals[j] <- totals[j]+1
  text(j-6,totals[j],pch=15,round(nulldiff,1))
  if(i < 20) Sys.sleep(1) ##You can add this line to see values appear slowly
}

# La figura anterior equivale a un histograma. A partir de un histograma del vector nulo que calculamos
# anteriormente, podemos ver que valores tan grandes como obsdiff son relativamente raros:
hist(null, freq=TRUE)
abline(v=obsdiff, col="red", lwd=2)


# DISTRIBUCIÓN NORMAL

# La distribución de probabilidad normal o distribución gaussiana es muy común en la naturaleza.
# Cuando una serie de datos tiene una distribución de probabilidad aproximadamente normal, la
# distribución teórica puede servir de comparación para calcular la proporción de valores por
# debajo (o por encima) de un valor x con pnorm(media=mu, desviación estándar=sigma) sin
# conocer todos los valores.

1 - pnorm(obsdiff,mean(null),sd(null)) 

# Solo necesitamos saber la media y la desviación estándar para describir toda la
# distribución; a partir de esto podemos calcular a proporción de valores en cualquier intervalo.

# Calcular el p-value para la diferencia en la dieta de los ratones fue fácil porque
# utilizamos el total de la población para definir la distribución nula con 10,000
# simulaciones. En la realidad esto rara vez es posible, afortunadamente existe la
# inferencia estadística que permite aproximar esto con datos muestrales.


# POBLACIÓN, MUESTRA Y ESTIMADORES

# Parámetros poblacionales:

# ¿Cuál es la población de interés?
# En el ejemplo: ratones hembras en dieta de control y ratones hembras en dietas altas en grasa.

#install.packages("downloader")
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- "mice_pheno.csv"
download(url,destfile=filename)
dat <- read.csv(filename)

# Dado que tenemos información de toda la población podemos calcular los parámetros poblacionales
# Tamaño de la población de control:

#Remover datos faltantes
dat <- na.omit(dat)

library(dplyr)
controlPopulation <- filter(dat,Sex == "F" & Diet == "chow") %>% select(Bodyweight) %>% unlist
nctrol <- length(controlPopulation)
# Denotamos estos valores como x(1), ..., x(n)

# Tamaño de la población con dieta alta en grasa:
hfPopulation <- filter(dat,Sex == "F" & Diet == "hf") %>% select(Bodyweight) %>% unlist
nhf <- length(hfPopulation)
# Denotamos estos como y(1),...,y(n)

# Estimar parámetros poblacionales
#install.packages("rafalib")
library(rafalib)

# Medias poblacionales
mean_ctrol <- mean(controlPopulation)
mean_hf <- mean(hfPopulation)

# Desviaciones
# (x(i)-media(x))
desv_ctrol <- (controlPopulation-mean_ctrol)

plot(1:nctrol, desv_ctrol, type="l",
     xlab="Observaciones",ylab="Desviación", main = "CONTROL")
abline(h=0, col="blue", lwd=2)

# (y(i)-media(y))
desv_hf <- (hfPopulation-mean_hf)

plot(1:nhf, desv_hf, type="l",
     xlab="Observaciones",ylab="Desviación", main = "ALTA EN GRASA")
abline(h=0, col="blue", lwd=2)

# ¿Qué indicador podría resumir el grado de variación de cada grupo de datos?

# Suma de desviaciones
sum_desv_ctrol <- round(sum(desv_ctrol),4)
sum_desv_hf <- round(sum(desv_hf),4)

# Desviaciones cuadradas
desv_2_ctrol <- (controlPopulation-mean_ctrol)^2

plot(1:nctrol, desv_2_ctrol, type="l",
     xlab="Observaciones",ylab="Desviación cuadratica", main = "CONTROL")
abline(h=0, col="blue", lwd=2)

desv_2_hf <- (hfPopulation-mean_hf)^2
plot(1:nhf, desv_2_hf, type="l",
     xlab="Observaciones",ylab="Desviación cuadratica", main = "ALTA EN GRASA")
abline(h=0, col="blue", lwd=2)

# Varianza poblacional
varpob_ctrol <- sum(desv_2_ctrol)/nctrol  # Promedio de las desviaciones cuadráticas
varpob_hf <- sum(desv_2_hf)/nhf

# Desviación estándar
sdpob_ctrol <- sqrt(varpob_ctrol)
sdpob_ctrol

sdpob_hf <- sqrt(varpob_hf)
sdpob_hf

# Estimación con la librería RAFALIB
popsd(controlPopulation)
popsd(hfPopulation)

# ESTIMACIONES MUESTRALES

# En el caso de las estimaciones con muestras aleatorias, la conceptualización de la varianza y la
# desviación estándar es la misma, pero el cálculo es ligeramente diferente: debe considerar los
# "grados de libertad", esto significa que la varianza debe divirse entre (n-1) en vez de (n)
# ¿Por qué?


# A una media m(x) dada, solo n-1 observaciones son independientes, es decir, se les puede asignar un
# valor con libertada, pero el último no porque queda automáticamente determinado por el valor asignado
# a los demás...

# Ejemplo
n = 5 # (tamaño de la muestra)
mean_x = 20 #media

# Asignar 4 valores de manera aleatoria
x1_4 <- sample(1:50,4,replace = TRUE)

# ¿Cuánto tiene que valer x(5) para que la media sea 20?
x5 <- (mean_x*n) - sum(x1_4)
x5

